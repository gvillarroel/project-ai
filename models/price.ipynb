{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Clase para cargar el tokenizador\n",
    "from transformers import AutoTokenizer\n",
    "# Clase para secuencias a clasificación (N -> 1)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# clases para entrenamiento\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# operative system\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"train_data.parquet\"\n",
    "TEST_FILE = \"test_data.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(TRAIN_FILE)\n",
    "df_test = pd.read_parquet(TEST_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_price(price_text):\n",
    "    value = int('0' + re.sub('[^0-9]', '', str(price_text)))\n",
    "\n",
    "    if \"uf\" in price_text.lower():\n",
    "        return value * 31000\n",
    "    return value\n",
    "# Convierto precio a numeros\n",
    "df_train[\"r_price\"] = df_train[\"price\"].map(get_price)\n",
    "df_test[\"r_price\"] = df_test[\"price\"].map(get_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_venta = df_train[df_train.operation == \"Venta\"].reset_index(drop=True)\n",
    "df_train_arriendo = df_train[df_train.operation == \"Arriendo\"].reset_index(drop=True)\n",
    "\n",
    "df_test_venta = df_test[df_test.operation == \"Venta\"].reset_index(drop=True)\n",
    "df_test_arriendo = df_test[df_test.operation == \"Arriendo\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selecciono el modelo base y creo un tokenizador para realizar pruebas\n",
    "MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# Imprimo el tamaño de la vocabulario\n",
    "display(tokenizer.vocab_size)\n",
    "# Imprimo los token especiales\n",
    "display(tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constante para entrenar o no\n",
    "TRAIN_MODE = False\n",
    "#MODEL_PATH=\"best_price/pytorch_model.bin\"\n",
    "MODEL_PATH =\"results/checkpoint-24372/pytorch_model.bin\"\n",
    "#SNAPSHOT=\"results/checkpoint-45846/pytorch_model.bin\"\n",
    "SNAPSHOT=None\n",
    "TRAIN_EPOCHS=10\n",
    "# Cuda si existe grafica, cpu si no\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el dataset, los minimos elementos a implementar son\n",
    "# __init__, __len__ y __getitem__\n",
    "# esto es porque itera con un for simple\n",
    "class PandasDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, df, x, y, tokenizer):    \n",
    "    self.x = df[x]\n",
    "    self.y = df[y]\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    return {\n",
    "                **self.tokenizer(self.x[ix], truncation=True, padding=\"max_length\", max_length=300),\n",
    "                **{\"label\": self.y[ix], \"text\": self.x[ix]}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Creo el modelo para clasificación, para el numero de label de nuestro problema\n",
    "# model_name es el nombre del modelo que quiero usar como base\n",
    "num_labels = 1\n",
    "model_venta = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "         .to(device))\n",
    "model_arriendo = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determino los parametros del entrenamiento\n",
    "BATCH_SIZE = 40\n",
    "logging_steps = len(df_train) // BATCH_SIZE\n",
    "training_args = TrainingArguments(output_dir=\"results\",\n",
    "                                  num_train_epochs=TRAIN_EPOCHS,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=BATCH_SIZE,\n",
    "                                  per_device_eval_batch_size=BATCH_SIZE,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  #metric_for_best_model=\"f1\",\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model_arriendo, args=training_args, train_dataset=PandasDataset(df_train_arriendo, \"description\", \"r_price\", tokenizer), eval_dataset=PandasDataset(df_test_arriendo, \"description\", \"r_price\", tokenizer))\n",
    "if TRAIN_MODE:\n",
    "    trainer.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results/checkpoint-2708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Dataset parecido al de entrenamiento, pero dedicado a predecir\n",
    "class PandasDatasetTest(torch.utils.data.Dataset):\n",
    "  def __init__(self, df, x, y, tokenizer):    \n",
    "    self.x = df[x]\n",
    "    self.y = df[y]\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    data = self.tokenizer(self.x[ix], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    return data[\"input_ids\"], data[\"attention_mask\"]\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(PandasDatasetTest(df_test_arriendo, \"description\", \"r_price\", tokenizer), batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_models = {}\n",
    "\n",
    "model = model_arriendo\n",
    "\n",
    "if not TRAIN_MODE:\n",
    "  model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "# Dejo al modelo en modo evaluación (evita calculos innecesarios)\n",
    "model.eval()\n",
    "\n",
    "# donde guardo los resultados\n",
    "s_results = []\n",
    "# itero por los batches del dataset de test\n",
    "for item in test_dataloader:\n",
    "  # Obtengo el batch de input_ids dimencion (B, 23, )\n",
    "  # 23 es el largo debido al padding\n",
    "  input_ids = torch.tensor(item[0]).to(device)\n",
    "  # Obtengo la mascara usada (B, 23, )\n",
    "  attention_mask = torch.tensor(item[1]).to(device)\n",
    "  # Obtengo el resultado \n",
    "  result = model(input_ids, attention_mask=attention_mask)\n",
    "  s_results.append([float(x) for x in result.logits])\n",
    "  # Borro los elemetos, importante para liberar memoria\n",
    "  del input_ids\n",
    "  del attention_mask\n",
    "  del result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1    2    3    4    5    6    7\n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "5  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "7  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df_test_arriendo\n",
    "\n",
    "df[\"y_pred\"] = [round(x) for x in np.concatenate([np.array(i) for i in s_results])]\n",
    "df[\"y_pred_float\"] = np.concatenate([np.array(i) for i in s_results])\n",
    "# Muestro los que no fueron bien asignados\n",
    "x_labels = list(range(1,8,1))\n",
    "y_labels = list(range(1,8,1))\n",
    "matrix = np.zeros((len(x_labels), len(y_labels)))\n",
    "for x in x_labels:\n",
    "  for y in y_labels: \n",
    "    matrix[x-1,y-1] = df.loc[(df.rooms == x) & (round(df.y_pred_float) == y)].shape[0]\n",
    "# Muestro la matrix\n",
    "display(pd.DataFrame(matrix, index=x_labels, columns=y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DOSQUE & RIQUELME PROPIEDADES ARRIENDA\\n\\nCaracterísticas de la unidad.  \\nDEPARTAMENTO CON VISTA ORIENTE, PISO 27, DE 2 DORMITORIOS, 1 BAÑOS, COCINA AMERICANA AMOBLADA Y EQUIPADA, PISO CERÁMICO EN ZONAS HÚMEDAS, AGUA CALIENTE POR TERMO ELÉCTRICO, INSTALACION DE LAVADORA Y BALCÓN.\\n\\nNO INCLUYE ESTACIONAMIENTO\\nNO INCLUYE BODEGA\\nGGCC APROX $50.000\\n\\nCaracterísticas del Edificio.  \\nHALL DE ACCESO EN DOBLE ALTURA, CONSERJERÍA, SALA MULTIUSO, PISCINA, GIMNASIO, LAVANDERÍA, QUINCHOS, ESTACIONAMIENTOS DE VISITA, SEGURIDAD CONTROLADA LAS 24 HORAS CON CÁMARAS DE VIGILANCIA.  \\n \\nInformación Adicional.  \\nGRAN CONECTIVIDAD DE LOCOMOCIÓN COLECTIVA MUY CERCA DE METRO ESTACIÓN IRARRÁZAVAL, SUPERMERCADOS, COMERCIO, OUTLET, PARQUE BUSTAMANTE, BANCOS, ETC. \\n\\nSOLICITE REQUISITOS Y CONDICIONES AL FORMULARIO DE CONTACTO\\nPARA ASEGURAR UNA ATENCIÓN APROPIADA, FAVOR LLAMAR DE LUNES A VIERNES ENTRE LAS 10:00 Y 18:00 HORAS\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://www.economicos.cl/propiedades/arriendo-2d1b-en-vicuna-mackenna-1207-codAAM7KZI.html'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[216.5208]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=320000\n",
      "y=126\n",
      "y_pred=216.52076721191406\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Sección de pruebas\n",
    "record = df_test_arriendo.sample(1).iloc[0]\n",
    "TEXTO_PRUEBA=record.description\n",
    "# Obtengo el vector y la mascara de uso\n",
    "input_ids, _, attention_mask = tokenizer(TEXTO_PRUEBA).values()\n",
    "# Paso a memoria de la grafica\n",
    "input_ids, attention_mask = torch.tensor(input_ids).unsqueeze(0).to(device), torch.tensor(attention_mask).unsqueeze(0).to(device)\n",
    "# Calculo\n",
    "result = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "print(\"=\"*30)\n",
    "display(record.description)\n",
    "display(record.url)\n",
    "print(\"=\"*30)\n",
    "display(result)\n",
    "print(f\"y={record.r_price}\")\n",
    "print(f\"y={record.n_price}\")\n",
    "print(f\"y_pred={record.y_pred_float}\")\n",
    "print(\"=\"*30)\n",
    "del result\n",
    "del input_ids\n",
    "del attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216403, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(24045, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.shape)\n",
    "display(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      11.0\n",
      "           1       0.00      0.00      0.00       2.0\n",
      "           3       0.00      0.00      0.00       1.0\n",
      "          22       0.00      0.00      0.00       1.0\n",
      "          30       0.00      0.00      0.00       2.0\n",
      "         100       0.00      0.00      0.00       1.0\n",
      "         150       0.00      0.00      0.00       1.0\n",
      "         160       0.00      0.00      0.00       1.0\n",
      "         200       0.00      0.00      0.00       1.0\n",
      "         217       0.00      0.00      0.00       0.0\n",
      "         220       0.00      0.00      0.00       1.0\n",
      "         240       0.00      0.00      0.00       1.0\n",
      "         300       0.00      0.00      0.00       1.0\n",
      "         340       0.00      0.00      0.00       1.0\n",
      "         350       0.00      0.00      0.00       1.0\n",
      "         360       0.00      0.00      0.00       1.0\n",
      "         400       0.00      0.00      0.00       2.0\n",
      "         420       0.00      0.00      0.00       1.0\n",
      "         470       0.00      0.00      0.00       1.0\n",
      "         499       0.00      0.00      0.00       1.0\n",
      "         580       0.00      0.00      0.00       1.0\n",
      "         680       0.00      0.00      0.00       1.0\n",
      "         700       0.00      0.00      0.00       1.0\n",
      "         720       0.00      0.00      0.00       1.0\n",
      "        2830       0.00      0.00      0.00       1.0\n",
      "        3000       0.00      0.00      0.00       1.0\n",
      "       11000       0.00      0.00      0.00       1.0\n",
      "       12000       0.00      0.00      0.00       1.0\n",
      "       16000       0.00      0.00      0.00       1.0\n",
      "       20000       0.00      0.00      0.00       1.0\n",
      "       22000       0.00      0.00      0.00       2.0\n",
      "       23000       0.00      0.00      0.00       3.0\n",
      "       24000       0.00      0.00      0.00       1.0\n",
      "       25000       0.00      0.00      0.00      12.0\n",
      "       26000       0.00      0.00      0.00       1.0\n",
      "       28000       0.00      0.00      0.00       2.0\n",
      "       29000       0.00      0.00      0.00       1.0\n",
      "       30000       0.00      0.00      0.00      28.0\n",
      "       32000       0.00      0.00      0.00       1.0\n",
      "       33000       0.00      0.00      0.00       2.0\n",
      "       35000       0.00      0.00      0.00      15.0\n",
      "       36000       0.00      0.00      0.00       1.0\n",
      "       38000       0.00      0.00      0.00       1.0\n",
      "       39000       0.00      0.00      0.00       1.0\n",
      "       40000       0.00      0.00      0.00      24.0\n",
      "       42000       0.00      0.00      0.00       2.0\n",
      "       43000       0.00      0.00      0.00       1.0\n",
      "       45000       0.00      0.00      0.00       5.0\n",
      "       48000       0.00      0.00      0.00       1.0\n",
      "       50000       0.00      0.00      0.00       4.0\n",
      "       54000       0.00      0.00      0.00       1.0\n",
      "       55000       0.00      0.00      0.00       4.0\n",
      "       60000       0.00      0.00      0.00       2.0\n",
      "       62000       0.00      0.00      0.00       1.0\n",
      "       65000       0.00      0.00      0.00       1.0\n",
      "       70000       0.00      0.00      0.00       1.0\n",
      "       75000       0.00      0.00      0.00       1.0\n",
      "       80000       0.00      0.00      0.00       1.0\n",
      "       85000       0.00      0.00      0.00       1.0\n",
      "       95000       0.00      0.00      0.00       1.0\n",
      "      100000       0.00      0.00      0.00       1.0\n",
      "      105000       0.00      0.00      0.00       1.0\n",
      "      110000       0.00      0.00      0.00       1.0\n",
      "      111111       0.00      0.00      0.00       1.0\n",
      "      115000       0.00      0.00      0.00       1.0\n",
      "      120000       0.00      0.00      0.00       3.0\n",
      "      125000       0.00      0.00      0.00       1.0\n",
      "      130000       0.00      0.00      0.00       4.0\n",
      "      135000       0.00      0.00      0.00       3.0\n",
      "      140000       0.00      0.00      0.00       7.0\n",
      "      150000       0.00      0.00      0.00      17.0\n",
      "      160000       0.00      0.00      0.00      12.0\n",
      "      165000       0.00      0.00      0.00       4.0\n",
      "      165225       0.00      0.00      0.00       1.0\n",
      "      169000       0.00      0.00      0.00       2.0\n",
      "      170000       0.00      0.00      0.00       9.0\n",
      "      175000       0.00      0.00      0.00       1.0\n",
      "      178000       0.00      0.00      0.00       1.0\n",
      "      180000       0.00      0.00      0.00      29.0\n",
      "      185000       0.00      0.00      0.00       5.0\n",
      "      185500       0.00      0.00      0.00       3.0\n",
      "      189000       0.00      0.00      0.00       1.0\n",
      "      190000       0.00      0.00      0.00      27.0\n",
      "      195000       0.00      0.00      0.00      15.0\n",
      "      200000       0.00      0.00      0.00     117.0\n",
      "      205000       0.00      0.00      0.00       1.0\n",
      "      210000       0.00      0.00      0.00      54.0\n",
      "      215000       0.00      0.00      0.00      14.0\n",
      "      219995       0.00      0.00      0.00       1.0\n",
      "      220000       0.00      0.00      0.00      98.0\n",
      "      221000       0.00      0.00      0.00       1.0\n",
      "      225000       0.00      0.00      0.00      21.0\n",
      "      229999       0.00      0.00      0.00       1.0\n",
      "      230000       0.00      0.00      0.00     140.0\n",
      "      235000       0.00      0.00      0.00      15.0\n",
      "      239990       0.00      0.00      0.00       1.0\n",
      "      240000       0.00      0.00      0.00     132.0\n",
      "      242000       0.00      0.00      0.00       1.0\n",
      "      245000       0.00      0.00      0.00      26.0\n",
      "      247500       0.00      0.00      0.00       1.0\n",
      "      249000       0.00      0.00      0.00       1.0\n",
      "      249999       0.00      0.00      0.00       1.0\n",
      "      250000       0.00      0.00      0.00     331.0\n",
      "      255000       0.00      0.00      0.00      15.0\n",
      "      255500       0.00      0.00      0.00       1.0\n",
      "      257000       0.00      0.00      0.00       2.0\n",
      "      258000       0.00      0.00      0.00       2.0\n",
      "      259000       0.00      0.00      0.00       1.0\n",
      "      259994       0.00      0.00      0.00       1.0\n",
      "      259999       0.00      0.00      0.00       2.0\n",
      "      260000       0.00      0.00      0.00     223.0\n",
      "      260999       0.00      0.00      0.00       1.0\n",
      "      262000       0.00      0.00      0.00       1.0\n",
      "      265000       0.00      0.00      0.00      31.0\n",
      "      267000       0.00      0.00      0.00       1.0\n",
      "      268000       0.00      0.00      0.00       2.0\n",
      "      269000       0.00      0.00      0.00       1.0\n",
      "      270000       0.00      0.00      0.00     232.0\n",
      "      275000       0.00      0.00      0.00      44.0\n",
      "      277000       0.00      0.00      0.00       1.0\n",
      "      277700       0.00      0.00      0.00       1.0\n",
      "      278000       0.00      0.00      0.00       1.0\n",
      "      279000       0.00      0.00      0.00       4.0\n",
      "      279900       0.00      0.00      0.00       1.0\n",
      "      279999       0.00      0.00      0.00       1.0\n",
      "      280000       0.00      0.00      0.00     350.0\n",
      "      284000       0.00      0.00      0.00       1.0\n",
      "      285000       0.00      0.00      0.00      42.0\n",
      "      287000       0.00      0.00      0.00       2.0\n",
      "      287500       0.00      0.00      0.00       1.0\n",
      "      288000       0.00      0.00      0.00       3.0\n",
      "      290000       0.00      0.00      0.00     254.0\n",
      "      294000       0.00      0.00      0.00       1.0\n",
      "      295000       0.00      0.00      0.00      59.0\n",
      "      298000       0.00      0.00      0.00       7.0\n",
      "      299000       0.00      0.00      0.00       2.0\n",
      "      299997       0.00      0.00      0.00       1.0\n",
      "      300000       0.00      0.00      0.00     530.0\n",
      "      302000       0.00      0.00      0.00       1.0\n",
      "      303500       0.00      0.00      0.00       1.0\n",
      "      305000       0.00      0.00      0.00       1.0\n",
      "      309995       0.00      0.00      0.00       1.0\n",
      "      310000       0.00      0.00      0.00     162.0\n",
      "      315000       0.00      0.00      0.00      26.0\n",
      "      317000       0.00      0.00      0.00       2.0\n",
      "      318000       0.00      0.00      0.00       1.0\n",
      "      319000       0.00      0.00      0.00       3.0\n",
      "      319998       0.00      0.00      0.00       2.0\n",
      "      319999       0.00      0.00      0.00       1.0\n",
      "      320000       0.00      0.00      0.00     391.0\n",
      "      325000       0.00      0.00      0.00      24.0\n",
      "      327000       0.00      0.00      0.00       2.0\n",
      "      327500       0.00      0.00      0.00       1.0\n",
      "      328000       0.00      0.00      0.00       1.0\n",
      "      329000       0.00      0.00      0.00       5.0\n",
      "      329900       0.00      0.00      0.00       3.0\n",
      "      329994       0.00      0.00      0.00       1.0\n",
      "      330000       0.00      0.00      0.00     308.0\n",
      "      332000       0.00      0.00      0.00       1.0\n",
      "      335000       0.00      0.00      0.00      18.0\n",
      "      336000       0.00      0.00      0.00       1.0\n",
      "      337000       0.00      0.00      0.00       3.0\n",
      "      338000       0.00      0.00      0.00       2.0\n",
      "      339000       0.00      0.00      0.00       1.0\n",
      "      339900       0.00      0.00      0.00       2.0\n",
      "      339997       0.00      0.00      0.00       1.0\n",
      "      340000       0.00      0.00      0.00     206.0\n",
      "      341000       0.00      0.00      0.00       6.0\n",
      "      345000       0.00      0.00      0.00      23.0\n",
      "      347000       0.00      0.00      0.00       1.0\n",
      "      349000       0.00      0.00      0.00       3.0\n",
      "      349900       0.00      0.00      0.00       1.0\n",
      "      349993       0.00      0.00      0.00       2.0\n",
      "      350000       0.00      0.00      0.00     750.0\n",
      "      350009       0.00      0.00      0.00       1.0\n",
      "      352999       0.00      0.00      0.00       1.0\n",
      "      355000       0.00      0.00      0.00       9.0\n",
      "      355500       0.00      0.00      0.00       2.0\n",
      "      358000       0.00      0.00      0.00       2.0\n",
      "      358672       0.00      0.00      0.00       1.0\n",
      "      359000       0.00      0.00      0.00       1.0\n",
      "      360000       0.00      0.00      0.00     264.0\n",
      "      362000       0.00      0.00      0.00       2.0\n",
      "      364000       0.00      0.00      0.00       1.0\n",
      "      365000       0.00      0.00      0.00      35.0\n",
      "      369000       0.00      0.00      0.00       5.0\n",
      "      369900       0.00      0.00      0.00       1.0\n",
      "      370000       0.00      0.00      0.00     222.0\n",
      "      372000       0.00      0.00      0.00       4.0\n",
      "      375000       0.00      0.00      0.00      34.0\n",
      "      378000       0.00      0.00      0.00       1.0\n",
      "      379000       0.00      0.00      0.00       2.0\n",
      "      379999       0.00      0.00      0.00       1.0\n",
      "      380000       0.00      0.00      0.00     434.0\n",
      "      385000       0.00      0.00      0.00      18.0\n",
      "      387500       0.00      0.00      0.00       1.0\n",
      "      389000       0.00      0.00      0.00       2.0\n",
      "      390000       0.00      0.00      0.00     251.0\n",
      "      393000       0.00      0.00      0.00       1.0\n",
      "      395000       0.00      0.00      0.00      37.0\n",
      "      398000       0.00      0.00      0.00       1.0\n",
      "      398585       0.00      0.00      0.00       1.0\n",
      "      399000       0.00      0.00      0.00       1.0\n",
      "      399990       0.00      0.00      0.00       1.0\n",
      "      399999       0.00      0.00      0.00       1.0\n",
      "      400000       0.00      0.00      0.00     536.0\n",
      "      401000       0.00      0.00      0.00       1.0\n",
      "      403000       0.00      0.00      0.00       5.0\n",
      "      405000       0.00      0.00      0.00      10.0\n",
      "      407000       0.00      0.00      0.00       1.0\n",
      "      410000       0.00      0.00      0.00      83.0\n",
      "      412000       0.00      0.00      0.00       2.0\n",
      "      415000       0.00      0.00      0.00      23.0\n",
      "      416000       0.00      0.00      0.00       1.0\n",
      "      419900       0.00      0.00      0.00       1.0\n",
      "      420000       0.00      0.00      0.00     275.0\n",
      "      425000       0.00      0.00      0.00      11.0\n",
      "      428000       0.00      0.00      0.00       1.0\n",
      "      429900       0.00      0.00      0.00       2.0\n",
      "      430000       0.00      0.00      0.00     208.0\n",
      "      434000       0.00      0.00      0.00      11.0\n",
      "      435000       0.00      0.00      0.00      14.0\n",
      "      440000       0.00      0.00      0.00      88.0\n",
      "      441000       0.00      0.00      0.00       1.0\n",
      "      445000       0.00      0.00      0.00       7.0\n",
      "      450000       0.00      0.00      0.00     537.0\n",
      "      451003       0.00      0.00      0.00       1.0\n",
      "      451439       0.00      0.00      0.00       1.0\n",
      "      455000       0.00      0.00      0.00       4.0\n",
      "      458000       0.00      0.00      0.00       1.0\n",
      "      459000       0.00      0.00      0.00       1.0\n",
      "      459993       0.00      0.00      0.00       1.0\n",
      "      460000       0.00      0.00      0.00     111.0\n",
      "      461440       0.00      0.00      0.00       1.0\n",
      "      462000       0.00      0.00      0.00       1.0\n",
      "      465000       0.00      0.00      0.00      15.0\n",
      "      470000       0.00      0.00      0.00      89.0\n",
      "      475000       0.00      0.00      0.00       7.0\n",
      "      476000       0.00      0.00      0.00       1.0\n",
      "      478000       0.00      0.00      0.00       1.0\n",
      "      479997       0.00      0.00      0.00       1.0\n",
      "      480000       0.00      0.00      0.00     203.0\n",
      "      485000       0.00      0.00      0.00       9.0\n",
      "      487000       0.00      0.00      0.00       1.0\n",
      "      490000       0.00      0.00      0.00      81.0\n",
      "      495000       0.00      0.00      0.00      20.0\n",
      "      496000       0.00      0.00      0.00       3.0\n",
      "      498000       0.00      0.00      0.00       3.0\n",
      "      499000       0.00      0.00      0.00       1.0\n",
      "      500000       0.00      0.00      0.00     349.0\n",
      "      505000       0.00      0.00      0.00       1.0\n",
      "      508000       0.00      0.00      0.00       1.0\n",
      "      510000       0.00      0.00      0.00      23.0\n",
      "      515000       0.00      0.00      0.00       6.0\n",
      "      520000       0.00      0.00      0.00      86.0\n",
      "      525000       0.00      0.00      0.00       8.0\n",
      "      526000       0.00      0.00      0.00       1.0\n",
      "      527000       0.00      0.00      0.00       6.0\n",
      "      530000       0.00      0.00      0.00      69.0\n",
      "      535000       0.00      0.00      0.00       4.0\n",
      "      540000       0.00      0.00      0.00      36.0\n",
      "      545000       0.00      0.00      0.00       8.0\n",
      "      550000       0.00      0.00      0.00     309.0\n",
      "      558000       0.00      0.00      0.00       5.0\n",
      "      559000       0.00      0.00      0.00       1.0\n",
      "      560000       0.00      0.00      0.00      44.0\n",
      "      565000       0.00      0.00      0.00       2.0\n",
      "      569537       0.00      0.00      0.00       1.0\n",
      "      570000       0.00      0.00      0.00      41.0\n",
      "      575000       0.00      0.00      0.00       5.0\n",
      "      580000       0.00      0.00      0.00      82.0\n",
      "      582000       0.00      0.00      0.00       1.0\n",
      "      585000       0.00      0.00      0.00       7.0\n",
      "      589000       0.00      0.00      0.00       4.0\n",
      "      590000       0.00      0.00      0.00      51.0\n",
      "      594810       0.00      0.00      0.00       1.0\n",
      "      595000       0.00      0.00      0.00      14.0\n",
      "      600000       0.00      0.00      0.00     245.0\n",
      "      603000       0.00      0.00      0.00       1.0\n",
      "      605000       0.00      0.00      0.00       1.0\n",
      "      610000       0.00      0.00      0.00      14.0\n",
      "      615000       0.00      0.00      0.00       3.0\n",
      "      619000       0.00      0.00      0.00       1.0\n",
      "      620000       0.00      0.00      0.00      47.0\n",
      "      625000       0.00      0.00      0.00       2.0\n",
      "      630000       0.00      0.00      0.00      43.0\n",
      "      634700       0.00      0.00      0.00       1.0\n",
      "      635000       0.00      0.00      0.00       2.0\n",
      "      638000       0.00      0.00      0.00       2.0\n",
      "      640000       0.00      0.00      0.00      14.0\n",
      "      645000       0.00      0.00      0.00       3.0\n",
      "      647000       0.00      0.00      0.00       1.0\n",
      "      650000       0.00      0.00      0.00     196.0\n",
      "      651000       0.00      0.00      0.00       9.0\n",
      "      660000       0.00      0.00      0.00      12.0\n",
      "      665000       0.00      0.00      0.00       2.0\n",
      "      670000       0.00      0.00      0.00      19.0\n",
      "      675000       0.00      0.00      0.00       3.0\n",
      "      680000       0.00      0.00      0.00      47.0\n",
      "      682000       0.00      0.00      0.00       6.0\n",
      "      685000       0.00      0.00      0.00       1.0\n",
      "      690000       0.00      0.00      0.00      36.0\n",
      "      695000       0.00      0.00      0.00       7.0\n",
      "      699000       0.00      0.00      0.00       1.0\n",
      "      699990       0.00      0.00      0.00       1.0\n",
      "      700000       0.00      0.00      0.00     133.0\n",
      "      705000       0.00      0.00      0.00       2.0\n",
      "      710000       0.00      0.00      0.00       9.0\n",
      "      713000       0.00      0.00      0.00       5.0\n",
      "      715000       0.00      0.00      0.00       1.0\n",
      "      720000       0.00      0.00      0.00      26.0\n",
      "      725000       0.00      0.00      0.00       2.0\n",
      "      728000       0.00      0.00      0.00       1.0\n",
      "      730000       0.00      0.00      0.00      13.0\n",
      "      735000       0.00      0.00      0.00       1.0\n",
      "      737000       0.00      0.00      0.00       1.0\n",
      "      740000       0.00      0.00      0.00       5.0\n",
      "      744000       0.00      0.00      0.00       4.0\n",
      "      745000       0.00      0.00      0.00       1.0\n",
      "      749000       0.00      0.00      0.00       1.0\n",
      "      750000       0.00      0.00      0.00     136.0\n",
      "      760000       0.00      0.00      0.00       9.0\n",
      "      770000       0.00      0.00      0.00       6.0\n",
      "      775000       0.00      0.00      0.00       3.0\n",
      "      779900       0.00      0.00      0.00       1.0\n",
      "      780000       0.00      0.00      0.00      32.0\n",
      "      785000       0.00      0.00      0.00       1.0\n",
      "      790000       0.00      0.00      0.00      18.0\n",
      "      795000       0.00      0.00      0.00       3.0\n",
      "      799000       0.00      0.00      0.00       1.0\n",
      "      800000       0.00      0.00      0.00      71.0\n",
      "      806000       0.00      0.00      0.00       5.0\n",
      "      810000       0.00      0.00      0.00       2.0\n",
      "      820000       0.00      0.00      0.00       8.0\n",
      "      825000       0.00      0.00      0.00       1.0\n",
      "      830000       0.00      0.00      0.00      10.0\n",
      "      837000       0.00      0.00      0.00       3.0\n",
      "      840000       0.00      0.00      0.00       7.0\n",
      "      849000       0.00      0.00      0.00       1.0\n",
      "      850000       0.00      0.00      0.00      65.0\n",
      "      860000       0.00      0.00      0.00       4.0\n",
      "      868000       0.00      0.00      0.00       5.0\n",
      "      870000       0.00      0.00      0.00       5.0\n",
      "      880000       0.00      0.00      0.00       5.0\n",
      "      890000       0.00      0.00      0.00      19.0\n",
      "      895000       0.00      0.00      0.00       1.0\n",
      "      899000       0.00      0.00      0.00       3.0\n",
      "      900000       0.00      0.00      0.00      54.0\n",
      "      905000       0.00      0.00      0.00       1.0\n",
      "      920000       0.00      0.00      0.00       2.0\n",
      "      930000       0.00      0.00      0.00       5.0\n",
      "      940000       0.00      0.00      0.00       1.0\n",
      "      945000       0.00      0.00      0.00       1.0\n",
      "      950000       0.00      0.00      0.00      44.0\n",
      "      960000       0.00      0.00      0.00       3.0\n",
      "      961000       0.00      0.00      0.00       4.0\n",
      "      962500       0.00      0.00      0.00       1.0\n",
      "      970000       0.00      0.00      0.00       2.0\n",
      "      975000       0.00      0.00      0.00       2.0\n",
      "      980000       0.00      0.00      0.00      15.0\n",
      "      990000       0.00      0.00      0.00      11.0\n",
      "      992000       0.00      0.00      0.00       2.0\n",
      "     1000000       0.00      0.00      0.00      41.0\n",
      "     1000050       0.00      0.00      0.00       1.0\n",
      "     1007000       0.00      0.00      0.00       1.0\n",
      "     1023000       0.00      0.00      0.00       5.0\n",
      "     1050000       0.00      0.00      0.00       7.0\n",
      "     1054000       0.00      0.00      0.00       1.0\n",
      "     1085000       0.00      0.00      0.00       4.0\n",
      "     1090000       0.00      0.00      0.00       2.0\n",
      "     1099000       0.00      0.00      0.00       1.0\n",
      "     1100000       0.00      0.00      0.00      32.0\n",
      "     1116000       0.00      0.00      0.00       1.0\n",
      "     1147000       0.00      0.00      0.00       2.0\n",
      "     1150000       0.00      0.00      0.00       6.0\n",
      "     1153575       0.00      0.00      0.00       1.0\n",
      "     1178000       0.00      0.00      0.00       1.0\n",
      "     1180000       0.00      0.00      0.00       1.0\n",
      "     1190000       0.00      0.00      0.00       3.0\n",
      "     1200000       0.00      0.00      0.00      65.0\n",
      "     1209000       0.00      0.00      0.00       2.0\n",
      "     1240000       0.00      0.00      0.00       5.0\n",
      "     1250000       0.00      0.00      0.00      11.0\n",
      "     1260000       0.00      0.00      0.00       1.0\n",
      "     1270000       0.00      0.00      0.00       1.0\n",
      "     1271000       0.00      0.00      0.00       3.0\n",
      "     1280000       0.00      0.00      0.00       1.0\n",
      "     1290000       0.00      0.00      0.00       1.0\n",
      "     1300000       0.00      0.00      0.00      37.0\n",
      "     1320000       0.00      0.00      0.00       1.0\n",
      "     1333000       0.00      0.00      0.00       3.0\n",
      "     1350000       0.00      0.00      0.00      11.0\n",
      "     1364000       0.00      0.00      0.00       2.0\n",
      "     1390000       0.00      0.00      0.00       1.0\n",
      "     1395000       0.00      0.00      0.00       6.0\n",
      "     1400000       0.00      0.00      0.00      22.0\n",
      "     1435000       0.00      0.00      0.00       1.0\n",
      "     1450000       0.00      0.00      0.00       3.0\n",
      "     1457000       0.00      0.00      0.00       1.0\n",
      "     1480000       0.00      0.00      0.00       1.0\n",
      "     1488000       0.00      0.00      0.00       2.0\n",
      "     1490000       0.00      0.00      0.00       3.0\n",
      "     1495000       0.00      0.00      0.00       1.0\n",
      "     1500000       0.00      0.00      0.00      26.0\n",
      "     1519000       0.00      0.00      0.00       2.0\n",
      "     1550000       0.00      0.00      0.00       6.0\n",
      "     1581000       0.00      0.00      0.00       1.0\n",
      "     1590000       0.00      0.00      0.00       1.0\n",
      "     1600000       0.00      0.00      0.00       8.0\n",
      "     1612000       0.00      0.00      0.00       1.0\n",
      "     1643000       0.00      0.00      0.00       1.0\n",
      "     1650000       0.00      0.00      0.00       4.0\n",
      "     1652000       0.00      0.00      0.00       1.0\n",
      "     1670000       0.00      0.00      0.00       1.0\n",
      "     1700000       0.00      0.00      0.00       7.0\n",
      "     1705000       0.00      0.00      0.00       3.0\n",
      "     1740000       0.00      0.00      0.00       1.0\n",
      "     1750000       0.00      0.00      0.00       2.0\n",
      "     1767000       0.00      0.00      0.00       1.0\n",
      "     1780000       0.00      0.00      0.00       1.0\n",
      "     1798000       0.00      0.00      0.00       1.0\n",
      "     1800000       0.00      0.00      0.00       7.0\n",
      "     1812545       0.00      0.00      0.00       1.0\n",
      "     1850000       0.00      0.00      0.00       7.0\n",
      "     1860000       0.00      0.00      0.00       6.0\n",
      "     1890000       0.00      0.00      0.00       1.0\n",
      "     1900000       0.00      0.00      0.00       2.0\n",
      "     1950000       0.00      0.00      0.00       3.0\n",
      "     1953000       0.00      0.00      0.00       1.0\n",
      "     2000000       0.00      0.00      0.00       6.0\n",
      "     2015000       0.00      0.00      0.00       1.0\n",
      "     2100000       0.00      0.00      0.00       4.0\n",
      "     2150000       0.00      0.00      0.00       1.0\n",
      "     2170000       0.00      0.00      0.00       2.0\n",
      "     2200000       0.00      0.00      0.00       1.0\n",
      "     2250000       0.00      0.00      0.00       1.0\n",
      "     2263000       0.00      0.00      0.00       3.0\n",
      "     2300000       0.00      0.00      0.00       4.0\n",
      "     2325000       0.00      0.00      0.00       2.0\n",
      "     2400000       0.00      0.00      0.00       3.0\n",
      "     2418000       0.00      0.00      0.00       1.0\n",
      "     2480000       0.00      0.00      0.00       1.0\n",
      "     2500000       0.00      0.00      0.00       9.0\n",
      "     2573000       0.00      0.00      0.00       1.0\n",
      "     2600000       0.00      0.00      0.00       2.0\n",
      "     2666000       0.00      0.00      0.00       2.0\n",
      "     2759000       0.00      0.00      0.00       1.0\n",
      "     2790000       0.00      0.00      0.00       2.0\n",
      "     2883000       0.00      0.00      0.00       1.0\n",
      "     2900000       0.00      0.00      0.00       1.0\n",
      "     2914000       0.00      0.00      0.00       1.0\n",
      "     2945000       0.00      0.00      0.00       3.0\n",
      "     3069000       0.00      0.00      0.00       1.0\n",
      "     3100000       0.00      0.00      0.00       3.0\n",
      "     3162000       0.00      0.00      0.00       1.0\n",
      "     3200000       0.00      0.00      0.00       7.0\n",
      "     3255000       0.00      0.00      0.00       1.0\n",
      "     3290000       0.00      0.00      0.00       1.0\n",
      "     3300000       0.00      0.00      0.00       1.0\n",
      "     3410000       0.00      0.00      0.00       1.0\n",
      "     3450000       0.00      0.00      0.00       1.0\n",
      "     3534000       0.00      0.00      0.00       1.0\n",
      "     3565000       0.00      0.00      0.00       3.0\n",
      "     3580000       0.00      0.00      0.00       1.0\n",
      "     3627000       0.00      0.00      0.00       1.0\n",
      "     3720000       0.00      0.00      0.00       2.0\n",
      "     3800000       0.00      0.00      0.00       1.0\n",
      "     3875000       0.00      0.00      0.00       2.0\n",
      "     3900000       0.00      0.00      0.00       1.0\n",
      "     3968000       0.00      0.00      0.00       1.0\n",
      "     4000000       0.00      0.00      0.00       1.0\n",
      "     4030000       0.00      0.00      0.00       2.0\n",
      "     4070000       0.00      0.00      0.00       1.0\n",
      "     4185000       0.00      0.00      0.00       1.0\n",
      "     4247000       0.00      0.00      0.00       1.0\n",
      "     4278000       0.00      0.00      0.00       1.0\n",
      "     4309000       0.00      0.00      0.00       1.0\n",
      "     4340000       0.00      0.00      0.00       2.0\n",
      "     4433000       0.00      0.00      0.00       1.0\n",
      "     4500000       0.00      0.00      0.00       2.0\n",
      "     4526000       0.00      0.00      0.00       1.0\n",
      "     4557000       0.00      0.00      0.00       1.0\n",
      "     4681000       0.00      0.00      0.00       1.0\n",
      "     4805000       0.00      0.00      0.00       1.0\n",
      "     4929000       0.00      0.00      0.00       1.0\n",
      "     4980000       0.00      0.00      0.00       1.0\n",
      "     5115000       0.00      0.00      0.00       2.0\n",
      "     5200000       0.00      0.00      0.00       1.0\n",
      "     5270000       0.00      0.00      0.00       1.0\n",
      "     5425000       0.00      0.00      0.00       2.0\n",
      "     5500000       0.00      0.00      0.00       1.0\n",
      "     5735000       0.00      0.00      0.00       4.0\n",
      "     6169000       0.00      0.00      0.00       1.0\n",
      "     6200000       0.00      0.00      0.00       1.0\n",
      "     6500000       0.00      0.00      0.00       1.0\n",
      "     6603000       0.00      0.00      0.00       1.0\n",
      "     6696000       0.00      0.00      0.00       1.0\n",
      "     6820000       0.00      0.00      0.00       1.0\n",
      "     7285000       0.00      0.00      0.00       1.0\n",
      "     7347000       0.00      0.00      0.00       1.0\n",
      "     7471000       0.00      0.00      0.00       1.0\n",
      "     7500000       0.00      0.00      0.00       1.0\n",
      "     7688000       0.00      0.00      0.00       1.0\n",
      "     7719000       0.00      0.00      0.00       2.0\n",
      "     7750000       0.00      0.00      0.00       1.0\n",
      "     8618000       0.00      0.00      0.00       1.0\n",
      "     8680000       0.00      0.00      0.00       1.0\n",
      "     9145000       0.00      0.00      0.00       1.0\n",
      "     9300000       0.00      0.00      0.00       2.0\n",
      "     9455000       0.00      0.00      0.00       1.0\n",
      "    10168000       0.00      0.00      0.00       1.0\n",
      "    10385000       0.00      0.00      0.00       1.0\n",
      "    11780000       0.00      0.00      0.00       1.0\n",
      "    12555000       0.00      0.00      0.00       1.0\n",
      "    14000000       0.00      0.00      0.00       1.0\n",
      "    14105000       0.00      0.00      0.00       1.0\n",
      "    15345000       0.00      0.00      0.00       1.0\n",
      "    17608000       0.00      0.00      0.00       1.0\n",
      "    20000000       0.00      0.00      0.00       1.0\n",
      "    20150000       0.00      0.00      0.00       1.0\n",
      "    21000000       0.00      0.00      0.00       1.0\n",
      "    25234000       0.00      0.00      0.00       1.0\n",
      "    32550000       0.00      0.00      0.00       1.0\n",
      "    33046000       0.00      0.00      0.00       1.0\n",
      "    33728000       0.00      0.00      0.00       1.0\n",
      "    34100000       0.00      0.00      0.00       1.0\n",
      "    34627000       0.00      0.00      0.00       1.0\n",
      "    34875000       0.00      0.00      0.00       1.0\n",
      "    36766000       0.00      0.00      0.00       1.0\n",
      "    39525000       0.00      0.00      0.00       1.0\n",
      "    39680000       0.00      0.00      0.00       1.0\n",
      "    40300000       0.00      0.00      0.00       1.0\n",
      "    40331000       0.00      0.00      0.00       1.0\n",
      "    42439000       0.00      0.00      0.00       1.0\n",
      "    42780000       0.00      0.00      0.00       1.0\n",
      "    43772000       0.00      0.00      0.00       1.0\n",
      "    43958000       0.00      0.00      0.00       1.0\n",
      "    44981000       0.00      0.00      0.00       1.0\n",
      "    48000000       0.00      0.00      0.00       1.0\n",
      "    48608000       0.00      0.00      0.00       1.0\n",
      "    51150000       0.00      0.00      0.00       1.0\n",
      "    51305000       0.00      0.00      0.00       1.0\n",
      "    52855000       0.00      0.00      0.00       1.0\n",
      "    53754000       0.00      0.00      0.00       1.0\n",
      "    54715000       0.00      0.00      0.00       1.0\n",
      "    56730000       0.00      0.00      0.00       1.0\n",
      "    58000000       0.00      0.00      0.00       1.0\n",
      "    59303000       0.00      0.00      0.00       1.0\n",
      "    59500000       0.00      0.00      0.00       1.0\n",
      "    61000000       0.00      0.00      0.00       1.0\n",
      "    62651000       0.00      0.00      0.00       1.0\n",
      "    64900000       0.00      0.00      0.00       1.0\n",
      "    65000000       0.00      0.00      0.00       1.0\n",
      "    71920000       0.00      0.00      0.00       1.0\n",
      "    77000000       0.00      0.00      0.00       1.0\n",
      "    78120000       0.00      0.00      0.00       1.0\n",
      "    86000000       0.00      0.00      0.00       2.0\n",
      "    88474000       0.00      0.00      0.00       1.0\n",
      "    95015000       0.00      0.00      0.00       1.0\n",
      "    95480000       0.00      0.00      0.00       1.0\n",
      "    95900000       0.00      0.00      0.00       1.0\n",
      "   100000000       0.00      0.00      0.00       1.0\n",
      "   101990000       0.00      0.00      0.00       1.0\n",
      "   105000000       0.00      0.00      0.00       1.0\n",
      "   110980000       0.00      0.00      0.00       1.0\n",
      "   114204000       0.00      0.00      0.00       1.0\n",
      "   115000000       0.00      0.00      0.00       1.0\n",
      "   117800000       0.00      0.00      0.00       1.0\n",
      "   120000000       0.00      0.00      0.00       1.0\n",
      "   142600000       0.00      0.00      0.00       1.0\n",
      "   144000000       0.00      0.00      0.00       1.0\n",
      "   145000000       0.00      0.00      0.00       1.0\n",
      "   145793000       0.00      0.00      0.00       1.0\n",
      "   173600000       0.00      0.00      0.00       1.0\n",
      "   179800000       0.00      0.00      0.00       1.0\n",
      "   185000000       0.00      0.00      0.00       1.0\n",
      "   207452000       0.00      0.00      0.00       1.0\n",
      "   275900000       0.00      0.00      0.00       1.0\n",
      "   279000000       0.00      0.00      0.00       1.0\n",
      "   289850000       0.00      0.00      0.00       1.0\n",
      "   300466784       0.00      0.00      0.00       1.0\n",
      "   330584000       0.00      0.00      0.00       1.0\n",
      "   387500000       0.00      0.00      0.00       1.0\n",
      "   458800000       0.00      0.00      0.00       1.0\n",
      "   480593000       0.00      0.00      0.00       1.0\n",
      "   508400000       0.00      0.00      0.00       1.0\n",
      "   574771000       0.00      0.00      0.00       1.0\n",
      "   589000000       0.00      0.00      0.00       1.0\n",
      " 10074690000       0.00      0.00      0.00       1.0\n",
      " 10850000000       0.00      0.00      0.00       1.0\n",
      " 17050000000       0.00      0.00      0.00       1.0\n",
      " 19530000000       0.00      0.00      0.00       1.0\n",
      " 24800000000       0.00      0.00      0.00       1.0\n",
      "124000000000       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00   12037.0\n",
      "   macro avg       0.00      0.00      0.00   12037.0\n",
      "weighted avg       0.00      0.00      0.00   12037.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerardo/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gerardo/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gerardo/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gerardo/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gerardo/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gerardo/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(df_test_arriendo.r_price.values, df_test_arriendo.y_pred.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'y_pred_float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31236/4187120347.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrooms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_pred_float\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'y_pred_float'"
     ]
    }
   ],
   "source": [
    "df_test[(df_test.rooms == df_test.y_pred_float.round())].shape[0] / df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[(df_test.rooms != df_test.y_pred)].to_csv(\"no_match.csv\", index=False)\n",
    "df_test.loc[(df_test.rooms != df_test.y_pred_float.round()), ['description', 'rooms', 'y_pred', 'y_pred_float']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[(df_test.rooms != df_test.y_pred_float.round())].iloc[0].description"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
