{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Clase para cargar el tokenizador\n",
    "from transformers import AutoTokenizer\n",
    "# Clase para secuencias a clasificación (N -> 1)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# clases para entrenamiento\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# operative system\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.683045008419857"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "log(130000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER=\"../data/economicos/data_cruda\"\n",
    "df = pd.concat([pd.read_json(f\"{DATA_FOLDER}/{imgfile}\") for imgfile in os.listdir(DATA_FOLDER)])\n",
    "df.to_parquet(\"../data/economicos/join.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"../data/economicos/join.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_FILE)\n",
    "df = df.rename(columns = {\n",
    "    'url': 'url',\n",
    "    'description': 'description',\n",
    "    'price': 'price',\n",
    "    'title': 'title',\n",
    "    'address': 'address',\n",
    "    'images': 'images',\n",
    "    'Tipo:': 'type',\n",
    "    'Operación:': 'operation',\n",
    "    'm  construidos:': 'm_built',\n",
    "    'm  terreno:': 'm_size',\n",
    "    'Región:': 'state',\n",
    "    'Comuna:': 'county',\n",
    "    'Fecha Publicación:': 'date',\n",
    "    'Diario:': 'source',\n",
    "    'Dormitorios:':'rooms',\n",
    "    'Baños:': 'bathrooms'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter = ((df.state == 'Metropolitana de Santiago') & (df['type'].isin(['Departamento', 'Casa', 'Departamento Amoblado'])) & (df['operation'].isin(['Arriendo', 'Venta'])) )\n",
    "#columns = ['description', 'price', 'm_built', 'm_size', 'county', 'date', 'rooms', 'bathrooms', 'title', 'url', 'operation']\n",
    "stgo = df[filter].drop_duplicates(subset='url').reset_index(drop=True)\n",
    "display(stgo.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import log\n",
    "stgo[\"n_price\"] = stgo.price.map(lambda x: int(\n",
    "    log(\n",
    "        int('0' + re.sub('[^0-9]', '', str(x)) )+1\n",
    "        )*10\n",
    "        )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stgo.price.head().map(lambda x: re.sub('[^0-9]', '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.DataFrame(stgo.n_price.value_counts())\n",
    "stgo.loc[stgo.n_price.isin(k[k.n_price==1].index.to_list()), \"n_price\"] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(stgo, test_size=0.1, stratify=stgo.n_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(\"train_data.parquet\")\n",
    "df_test.to_parquet(\"test_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216403, 17)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(24045, 17)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.shape)\n",
    "display(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stgo.description.iloc[0])\n",
    "display(stgo.rooms.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stgo[(stgo.rooms<1) | (stgo.rooms>6)].shape[0])\n",
    "stgo_rooms = stgo[(stgo.rooms>=1) & (stgo.rooms<=6)]\n",
    "display(stgo_rooms.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stgo_rooms.rooms.agg(['min', 'max']))\n",
    "stgo_rooms['n_rooms'] = (stgo_rooms.rooms-stgo_rooms.rooms.min())/(stgo_rooms.rooms.max()-stgo_rooms.rooms.min())\n",
    "\n",
    "display(stgo_rooms.n_rooms.agg(['min', 'max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciono el modelo base y creo un tokenizador para realizar pruebas\n",
    "model_name = \"dccuchile/bert-base-spanish-wwm-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Imprimo el tamaño de la vocabulario\n",
    "display(tokenizer.vocab_size)\n",
    "# Imprimo los token especiales\n",
    "display(tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constante para entrenar o no\n",
    "TRAIN_MODE = True\n",
    "MODEL_PATH=\"best_rooms/15282-1.34102135/pytorch_model.bin\"\n",
    "#SNAPSHOT=\"results/checkpoint-45846/pytorch_model.bin\"\n",
    "SNAPSHOT=None\n",
    "TRAIN_EPOCHS=20\n",
    "# Cuda si existe grafica, cpu si no\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datasets\n",
    "df_train, df_test = train_test_split(stgo_rooms, test_size=0.1, stratify=stgo_rooms.rooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reseteo el index, importante para crear los datasets\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.description.map(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el dataset, los minimos elementos a implementar son\n",
    "# __init__, __len__ y __getitem__\n",
    "# esto es porque itera con un for simple\n",
    "class PandasDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, df, x, y, tokenizer):    \n",
    "    self.x = df[x]\n",
    "    self.y = df[y]\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    return {\n",
    "                **self.tokenizer(self.x[ix], truncation=True, padding=\"max_length\", max_length=300),\n",
    "                **{\"label\": self.y[ix], \"text\": self.x[ix]}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el modelo para clasificación, para el numero de label de nuestro problema\n",
    "# model_name es el nombre del modelo que quiero usar como base\n",
    "num_labels = 1\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_name, num_labels=num_labels)\n",
    "         .to(device))\n",
    "if SNAPSHOT:\n",
    "    model.load_state_dict(torch.load(SNAPSHOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determino los parametros del entrenamiento\n",
    "BATCH_SIZE = 40\n",
    "logging_steps = len(df_train) // BATCH_SIZE\n",
    "training_args = TrainingArguments(output_dir=\"results\",\n",
    "                                  num_train_epochs=TRAIN_EPOCHS,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=BATCH_SIZE,\n",
    "                                  per_device_eval_batch_size=BATCH_SIZE,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  #metric_for_best_model=\"f1\",\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args, train_dataset=PandasDataset(df_train, \"description\", \"rooms\", tokenizer), eval_dataset=PandasDataset(df_test, \"description\", \"rooms\", tokenizer))\n",
    "if TRAIN_MODE:\n",
    "  trainer.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results/checkpoint-4284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Dataset parecido al de entrenamiento, pero dedicado a predecir\n",
    "class PandasDatasetTest(torch.utils.data.Dataset):\n",
    "  def __init__(self, df, x, y, tokenizer):    \n",
    "    self.x = df[x]\n",
    "    self.y = df[y]\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    data = self.tokenizer(self.x[ix], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    return data[\"input_ids\"], data[\"attention_mask\"]\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(PandasDatasetTest(df_test, \"description\", \"rooms\", tokenizer), batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_models = {}\n",
    "\n",
    "if not TRAIN_MODE:\n",
    "  model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "# Dejo al modelo en modo evaluación (evita calculos innecesarios)\n",
    "model.eval()\n",
    "\n",
    "# donde guardo los resultados\n",
    "s_results = []\n",
    "# itero por los batches del dataset de test\n",
    "for item in test_dataloader:\n",
    "  # Obtengo el batch de input_ids dimencion (B, 23, )\n",
    "  # 23 es el largo debido al padding\n",
    "  input_ids = torch.tensor(item[0]).to(device)\n",
    "  # Obtengo la mascara usada (B, 23, )\n",
    "  attention_mask = torch.tensor(item[1]).to(device)\n",
    "  # Obtengo el resultado \n",
    "  result = model(input_ids, attention_mask=attention_mask)\n",
    "  s_results.append([float(x) for x in result.logits])\n",
    "  # Borro los elemetos, importante para liberar memoria\n",
    "  del input_ids\n",
    "  del attention_mask\n",
    "  del result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_test\n",
    "\n",
    "df[\"y_pred\"] = [round(x) for x in np.concatenate([np.array(i) for i in s_results])]\n",
    "df[\"y_pred_float\"] = np.concatenate([np.array(i) for i in s_results])\n",
    "# Muestro los que no fueron bien asignados\n",
    "x_labels = list(range(1,8,1))\n",
    "y_labels = list(range(1,8,1))\n",
    "matrix = np.zeros((len(x_labels), len(y_labels)))\n",
    "for x in x_labels:\n",
    "  for y in y_labels: \n",
    "    matrix[x-1,y-1] = df.loc[(df.rooms == x) & (round(df.y_pred_float) == y)].shape[0]\n",
    "# Muestro la matrix\n",
    "display(pd.DataFrame(matrix, index=x_labels, columns=y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección de pruebas\n",
    "record = df_test[(df_test.rooms != df_test.y_pred_float.round())].iloc[6]\n",
    "TEXTO_PRUEBA=record.description\n",
    "# Obtengo el vector y la mascara de uso\n",
    "input_ids, _, attention_mask = tokenizer(TEXTO_PRUEBA).values()\n",
    "# Paso a memoria de la grafica\n",
    "input_ids, attention_mask = torch.tensor(input_ids).unsqueeze(0).to(device), torch.tensor(attention_mask).unsqueeze(0).to(device)\n",
    "# Calculo\n",
    "result = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "print(\"=\"*30)\n",
    "display(record.description)\n",
    "display(record.url)\n",
    "print(\"=\"*30)\n",
    "display(result)\n",
    "print(f\"y={record.rooms}\")\n",
    "print(f\"y_pred={record.y_pred_float}\")\n",
    "print(\"=\"*30)\n",
    "del result\n",
    "del input_ids\n",
    "del attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[(df_test.rooms == df_test.y_pred_float.round())].shape[0] / df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[(df_test.rooms != df_test.y_pred)].to_csv(\"no_match.csv\", index=False)\n",
    "df_test.loc[(df_test.rooms != df_test.y_pred_float.round()), ['description', 'rooms', 'y_pred', 'y_pred_float']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[(df_test.rooms != df_test.y_pred_float.round())].iloc[0].description"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
