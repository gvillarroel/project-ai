{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Análisis transformer\n",
    "Para el segundo chatbot utilice un transformer (por ejemplo BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer punto\n",
    "Utilice el modelo transformer para clasificar el texto de entrada, y para\n",
    "extraer la respuesta de la tabla de preguntas y respuestas cuando el\n",
    "mensaje sea del tipo “información”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librería para manipular la data\n",
    "import pandas as pd\n",
    "# Librería para utilizar transformers\n",
    "# Las \"pipeline\" permite utilizar multiples capas de transformers\n",
    "# pueden tomar predefinidas arquitecturas en huggingface\n",
    "# https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "from transformers import pipeline\n",
    "# Importo torch que se utilizara para entrenar el modelo\n",
    "import torch\n",
    "# Clase para cargar el tokenizador\n",
    "from transformers import AutoTokenizer\n",
    "# Clase para secuencias a clasificación (N -> 1)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# clases para entrenamiento\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# enumeraciones\n",
    "from enum import Enum\n",
    "\n",
    "# Para ignorar warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_PATH = \"../data/FAQ/tablaQA.xls\"\n",
    "RESPUESTAS_DEFECTO_PATH = \"../data/FAQ/respuestasDefecto.xls\"\n",
    "TIPOS_MENSAJES_PATH = \"../data/FAQ/tiposmensajes.xlsx\"\n",
    "TIPOS_MENSAJES_TEST_PATH = \"../data/FAQ/tiposmensajes_test.xlsx\"\n",
    "# Cargo un modelo preentrenado en español\n",
    "#MODEL_NAME='mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es'\n",
    "MODEL_NAME=\"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\"\n",
    "class TipoMensaje(Enum):\n",
    "    Saludo = \"saludo\"\n",
    "    Despedida = \"despedida\"\n",
    "    Nombre = \"nombre\"\n",
    "    Informacion = \"informacion\"\n",
    "    def __str__(self) -> str:\n",
    "        return self.value\n",
    "    def __eq__(self, __o: str) -> bool:\n",
    "        return __o == self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargo QA dataframe\n",
    "df_qa = pd.read_excel(QA_PATH)\n",
    "df_qa['Preguntas'] = df_qa.Preguntas.map(str.strip)\n",
    "# cargo Respuestas dataframe\n",
    "df_respuestas = pd.read_excel(RESPUESTAS_DEFECTO_PATH)\n",
    "# cargo Tipo Mensajes dataframe\n",
    "df_tipo_mensajes = pd.read_excel(TIPOS_MENSAJES_PATH)\n",
    "df_tipo_mensajes_test = pd.read_excel(TIPOS_MENSAJES_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num</th>\n",
       "      <th>Preguntas</th>\n",
       "      <th>Respuestas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>¿Qué es la Encuesta Casen?</td>\n",
       "      <td>La Encuesta de Caracterización Socioeconómica ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>¿Qué instituciones participan en la realizació...</td>\n",
       "      <td>Las instituciones que participan en la realiza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>¿Cada cuánto tiempo se realiza la Encuesta Casen?</td>\n",
       "      <td>La Encuesta Casen es realizada regularmente po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>¿Cuál es el tamaño de la muestra de la Encuest...</td>\n",
       "      <td>El tamaño de la muestra y su nivel de precisió...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>¿Se puede acceder a las bases de datos de la E...</td>\n",
       "      <td>Sí. Las bases de datos innominadas de la Encue...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num                                          Preguntas  \\\n",
       "0    1                         ¿Qué es la Encuesta Casen?   \n",
       "1    2  ¿Qué instituciones participan en la realizació...   \n",
       "2    3  ¿Cada cuánto tiempo se realiza la Encuesta Casen?   \n",
       "3    4  ¿Cuál es el tamaño de la muestra de la Encuest...   \n",
       "4    5  ¿Se puede acceder a las bases de datos de la E...   \n",
       "\n",
       "                                          Respuestas  \n",
       "0  La Encuesta de Caracterización Socioeconómica ...  \n",
       "1  Las instituciones que participan en la realiza...  \n",
       "2  La Encuesta Casen es realizada regularmente po...  \n",
       "3  El tamaño de la muestra y su nivel de precisió...  \n",
       "4  Sí. Las bases de datos innominadas de la Encue...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se genera un modelo para clasificar el texto en:\n",
    "1. Saludo\n",
    "1. Despedida\n",
    "1. Nombre\n",
    "1. Información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un dataset para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [TipoMensaje.Saludo, TipoMensaje.Despedida, TipoMensaje.Nombre, TipoMensaje.Informacion]\n",
    "LABELS = list(map(str, LABELS))\n",
    "df_tipo_mensajes[\"label\"] = df_tipo_mensajes.Tipo.map(lambda tipo: [tipo == label for label in LABELS])\n",
    "df_tipo_mensajes_test[\"label\"] = df_tipo_mensajes_test.Tipo.map(lambda tipo: [tipo == label for label in LABELS])\n",
    "# Creo el dataset, los minimos elementos a implementar son\n",
    "# __init__, __len__ y __getitem__\n",
    "# esto es porque itera con un for simple\n",
    "class PandasDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, df, x, y, tokenizer):    \n",
    "    self.x = df[x]\n",
    "    self.y = df[y]\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    return {\n",
    "                **self.tokenizer(self.x[ix], truncation=True, padding=\"max_length\", max_length=50),\n",
    "                **{\"label\": self.y[ix], \"text\": self.x[ix]}\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el modelo a entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es were not used when initializing BertForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# Creo el modelo para clasificación, para el numero de label de nuestro problema\n",
    "# model_name es el nombre del modelo que quiero usar como base\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_LABELS = len(LABELS)\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(MODEL_NAME, num_labels=NUM_LABELS, id2label=LABELS)\n",
    "         .to(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se configura los parametros de entrenamientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determino los parametros del entrenamiento\n",
    "BATCH_SIZE = 2\n",
    "TRAIN_EPOCHS=10\n",
    "logging_steps = len(df_qa) // BATCH_SIZE\n",
    "training_args = TrainingArguments(output_dir=\"results\",\n",
    "                                  num_train_epochs=TRAIN_EPOCHS,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=BATCH_SIZE,\n",
    "                                  per_device_eval_batch_size=BATCH_SIZE,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  #metric_for_best_model=\"f1\",\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena el modelo seleccionado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Obs.* Por la cantidad baja de ejemplos, se útiliza todos los registros para el entrenamiento, pero en un caso real, debería separarse un subset para validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 115\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 580\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 44\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to results/checkpoint-58\n",
      "Configuration saved in results/checkpoint-58/config.json\n",
      "Model weights saved in results/checkpoint-58/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 44\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to results/checkpoint-116\n",
      "Configuration saved in results/checkpoint-116/config.json\n",
      "Model weights saved in results/checkpoint-116/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 44\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to results/checkpoint-174\n",
      "Configuration saved in results/checkpoint-174/config.json\n",
      "Model weights saved in results/checkpoint-174/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 44\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to results/checkpoint-232\n",
      "Configuration saved in results/checkpoint-232/config.json\n",
      "Model weights saved in results/checkpoint-232/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 44\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to results/checkpoint-290\n",
      "Configuration saved in results/checkpoint-290/config.json\n",
      "Model weights saved in results/checkpoint-290/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 44\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to results/checkpoint-348\n",
      "Configuration saved in results/checkpoint-348/config.json\n",
      "Model weights saved in results/checkpoint-348/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 44\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to results/checkpoint-406\n",
      "Configuration saved in results/checkpoint-406/config.json\n",
      "Model weights saved in results/checkpoint-406/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 44\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to results/checkpoint-464\n",
      "Configuration saved in results/checkpoint-464/config.json\n",
      "Model weights saved in results/checkpoint-464/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 44\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to results/checkpoint-522\n",
      "Configuration saved in results/checkpoint-522/config.json\n",
      "Model weights saved in results/checkpoint-522/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 44\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to results/checkpoint-580\n",
      "Configuration saved in results/checkpoint-580/config.json\n",
      "Model weights saved in results/checkpoint-580/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-580 (score: 0.016288774088025093).\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "training_dateset = PandasDataset(df_tipo_mensajes, \"Mensaje\", \"label\", tokenizer)\n",
    "test_dateset = PandasDataset(df_tipo_mensajes_test, \"Mensaje\", \"label\", tokenizer)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=training_dateset, eval_dataset=test_dateset)\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa['Preguntas'] = df_qa.Preguntas.map(str.strip)\n",
    "# cargo Respuestas dataframe\n",
    "df_respuestas = pd.read_excel(RESPUESTAS_DEFECTO_PATH)\n",
    "# cargo Tipo Mensajes dataframe\n",
    "df_tipo_mensajes = pd.read_excel(TIPOS_MENSAJES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el bot para responder según el tipo de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bot():\n",
    "    def __init__(self, pipe_qa, context, pipe_classifier, df_respuestas) -> None:\n",
    "        self.pipe_qa = pipe_qa\n",
    "        self.context = context\n",
    "        self.classifier = pipe_classifier\n",
    "        self.df_respuestas = df_respuestas\n",
    "        self.nombre = None\n",
    "        self.chat = []\n",
    "    def __call__(self, text) -> str:\n",
    "        # Guardo el texto en la lista\n",
    "        self.chat.append(f\"Usuario: {text}\")\n",
    "        # determino la clase de entrada\n",
    "        clase = self.classifier(text)[0][\"label\"]\n",
    "        \n",
    "        if clase == TipoMensaje.Saludo:\n",
    "            self.saludar(text)\n",
    "        elif clase == TipoMensaje.Despedida:\n",
    "            self.despedirse(text)\n",
    "        elif clase == TipoMensaje.Nombre:\n",
    "            self.guardarNombre(text)\n",
    "        elif clase == TipoMensaje.Informacion:\n",
    "            self.responder(text)\n",
    "        return \"\\n\".join(self.chat)\n",
    "    def replyBot(self, text):\n",
    "        self.chat.append(f\"Bot: {text}\")\n",
    "    def saludar(self, text):\n",
    "        saludo = self.df_respuestas[self.df_respuestas.tipo == TipoMensaje.Saludo].sample(1).respuesta.iloc[0]\n",
    "        if self.nombre is None:\n",
    "            saludo = f\"{saludo}, ¿cual es tu nombre?\"\n",
    "        self.replyBot(saludo)\n",
    "    def despedirse(self, text):\n",
    "        self.replyBot(\n",
    "            self.df_respuestas[self.df_respuestas.tipo == TipoMensaje.Despedida].sample(1).respuesta.iloc[0]\n",
    "            )\n",
    "    def responder(self, text):\n",
    "        self.replyBot(\n",
    "            self.pipe_qa(question=text, context=self.context)[\"answer\"]\n",
    "        )\n",
    "    def guardarNombre(self, text):\n",
    "        self.nombre = text\n",
    "        self.replyBot(f\"mucho gusto {self.nombre}\")\n",
    "        self.replyBot(\"¿en que podemos ayudarte?\")\n",
    "    def __repr__(self) -> str:\n",
    "        return \"\\n\".join(self.chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at /home/gerardo/.cache/huggingface/transformers/17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at /home/gerardo/.cache/huggingface/transformers/17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/pytorch_model.bin from cache at /home/gerardo/.cache/huggingface/transformers/7966a0423b1c913c4e68d5399e17e4296eb2a7445564ae9ec574ae547efbe8bd.14d8bb83a1f0f787ccc04af18ea2125ec4a26e94474747d8b5834fb315e2caa4\n",
      "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at /home/gerardo/.cache/huggingface/transformers/17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/vocab.txt from cache at /home/gerardo/.cache/huggingface/transformers/2c511a62e569bb7e3623cdadba0823aa6ac3953d13dc7401f40a47794cea3079.dafbd6e6622cfaafea54bfe717b14fcacdaa069149af8fae4086afa5a9629ec3\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/special_tokens_map.json from cache at /home/gerardo/.cache/huggingface/transformers/9ee3712830b330cf2407b46bba34b1ca9dbeab6c887b79991d4053ca40501c8f.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/tokenizer_config.json from cache at /home/gerardo/.cache/huggingface/transformers/4d0cfa842922c935f9584d98c1de673525620c32f5749db976f4dd568d90bc76.f57c45f436182a8fb3a56f7b1c341ed2943046fed9922b6963a46c869a9196aa\n",
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at /home/gerardo/.cache/huggingface/transformers/17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at /home/gerardo/.cache/huggingface/transformers/17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "pipe_qa = pipeline(\"question-answering\", model=MODEL_NAME)\n",
    "context = \"\\n\".join(df_qa.Respuestas.values)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=0 if device==\"cuda\" else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo punto\n",
    "Reporte el tipo de red, y las métricas de entrenamiento usadas. Si requiere generar más ejemplos puede generar variaciones de sus tablas\n",
    "usando el tutorial del www.github.com/makcedward/nlpaug/blob/\n",
    "master/example/textual\\_augmenter.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ambos modelos se utilizó `BertForQuestionAnswering` con los pesos `mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es`, pero con las herramientas de huggingface se modifica el modelo para utilizarlo para clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto permite la transformación a `BertForSequenceClassification` y ajustarlo a un clasificador de 4 clases con\n",
    "```\n",
    "(classifier): Linear(in_features=768, out_features=4, bias=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificador(text):\n",
    "    return classifier(text)[0]['label']\n",
    "\n",
    "df_tipo_mensajes_test[\"y_pred\"] = df_tipo_mensajes_test.Mensaje.map(clasificador)\n",
    "y_true = df_tipo_mensajes_test[\"Tipo\"].map(LABELS.index).values\n",
    "y_pred = df_tipo_mensajes_test[\"y_pred\"].map(LABELS.index).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        44\n",
      "   macro avg       1.00      1.00      1.00        44\n",
      "weighted avg       1.00      1.00      1.00        44\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5,  0,  0,  0],\n",
       "       [ 0,  3,  0,  0],\n",
       "       [ 0,  0, 30,  0],\n",
       "       [ 0,  0,  0,  6]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(y_true, y_pred))\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tercer Punto\n",
    "Reporte el resultado con los textos de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se prueba pregunta respuesta pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6107734441757202,\n",
       " 'start': 5231,\n",
       " 'end': 5282,\n",
       " 'answer': 'Encuesta de Caracterización Socioeconómica Nacional'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_qa(question=\"¿Que es la CASEN?\", context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se prueba en conjunto el robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuario: Hola\n",
      "Bot: Buenos días, ¿cual es tu nombre?\n",
      "Usuario: Gerardo Villarroel\n",
      "Bot: mucho gusto Gerardo Villarroel\n",
      "Bot: ¿en que podemos ayudarte?\n",
      "Usuario: me gustaría saber que es la encuesta CASEN\n",
      "Bot: un instrumento aplicado a una muestra aleatoria y anónima de hogares\n",
      "Usuario: que es la CASEN?\n",
      "Bot: Encuesta de Caracterización Socioeconómica Nacional\n",
      "Usuario: chao\n",
      "Bot: Adiós!\n"
     ]
    }
   ],
   "source": [
    "bot = Bot(pipe_qa, context, classifier, df_respuestas)\n",
    "bot(\"Hola\")\n",
    "bot(\"Gerardo Villarroel\")\n",
    "bot(\"me gustaría saber que es la encuesta CASEN\")\n",
    "bot(\"que es la CASEN?\")\n",
    "print(bot(\"chao\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
