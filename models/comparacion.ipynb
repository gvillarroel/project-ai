{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Clase para cargar el tokenizador\n",
    "from transformers import AutoTokenizer\n",
    "# Clase para secuencias a clasificación (N -> 1)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# clases para entrenamiento\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# operative system\n",
    "import os\n",
    "\n",
    "from transformers import pipeline                                                   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN = \"train_data.parquet\"\n",
    "DATA_TEST = \"test_data.parquet\"\n",
    "# Carga de datasets\n",
    "df_train = pd.read_parquet(DATA_TRAIN).reset_index(drop=True)\n",
    "df_test = pd.read_parquet(DATA_TEST).reset_index(drop=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH=\"best_bathrooms/pytorch_model.bin\"\n",
    "MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-uncased\"\n",
    "\n",
    "NUM_LABELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.weight', 'classifier.weight', 'bert.pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(MODEL_NAME, num_labels=NUM_LABELS))\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Excelente casa grande con mas de 400m2, 4 habitaciones, 2 baños, sala, cocina, comedor, estacionamiento para 3, jardin y terreno. Buena ubicación a 2 cuadras de estacion del metro',\n",
       " 'Departamento ubicado en Condominio El Jardín del Llano. 3 dormitorios, 2 baños, estacionamiento (uso y goce), bodega. 72 m2 aprox.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[[2.006520986557007]], [[1.9985408782958984]]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\"feature-extraction\", model=model, tokenizer=tokenizer)\n",
    "display([df_test.iloc[0].description, df_test.iloc[1].description])\n",
    "display(pipe([df_test.iloc[0].description, df_test.iloc[1].description]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Excelente casa grande con mas de 400m2, 4 habitaciones, 2 baños, sala, cocina, comedor, estacionamiento para 3, jardin y terreno. Buena ubicación a 2 cuadras de estacion del metro'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Excelente casa grande con mas de 400m2, 4 habitaciones, 2 baños, sala, cocina, comedor, estacionamiento para 3, jardin y terreno. Buena ubicación a 2 cuadras de estacion del metro'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.8814799785614014}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_test.iloc[0].description)\n",
    "display(pipe(df_test.iloc[0].description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Departamento ubicado en Condominio El Jardín del Llano. 3 dormitorios, 2 baños, estacionamiento (uso y goce), bodega. 72 m2 aprox.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.8806438446044922}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_test.iloc[1].description)\n",
    "display(pipe(df_test.iloc[1].description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Dataset parecido al de entrenamiento, pero dedicado a predecir\n",
    "class PandasDatasetTest(torch.utils.data.Dataset):\n",
    "  def __init__(self, df, x, y, tokenizer):    \n",
    "    self.x = df[x]\n",
    "    self.y = df[y]\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    data = self.tokenizer(self.x[ix], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    return data[\"input_ids\"], data[\"attention_mask\"]\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(PandasDatasetTest(df_test, \"description\", \"bathrooms\", tokenizer), batch_size=20, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_models = {}\n",
    "\n",
    "if not TRAIN_MODE:\n",
    "  model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "# Dejo al modelo en modo evaluación (evita calculos innecesarios)\n",
    "model.eval()\n",
    "\n",
    "# donde guardo los resultados\n",
    "s_results = []\n",
    "# itero por los batches del dataset de test\n",
    "for item in test_dataloader:\n",
    "  # Obtengo el batch de input_ids dimencion (B, 23, )\n",
    "  # 23 es el largo debido al padding\n",
    "  input_ids = torch.tensor(item[0]).to(device)\n",
    "  # Obtengo la mascara usada (B, 23, )\n",
    "  attention_mask = torch.tensor(item[1]).to(device)\n",
    "  # Obtengo el resultado \n",
    "  result = model(input_ids, attention_mask=attention_mask)\n",
    "  s_results.append([float(x) for x in result.logits])\n",
    "  # Borro los elemetos, importante para liberar memoria\n",
    "  del input_ids\n",
    "  del attention_mask\n",
    "  del result\n",
    "\n",
    "df[\"y_pred\"] = [round(x) for x in np.concatenate([np.array(i) for i in s_results])]\n",
    "df[\"y_pred_float\"] = np.concatenate([np.array(i) for i in s_results])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
